{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London Housing and Population Analysis (2002 - 2015 data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial EDA of House Sales Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13549 entries, 0 to 13548\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           13549 non-null  object \n",
      " 1   area           13549 non-null  object \n",
      " 2   average_price  13549 non-null  int64  \n",
      " 3   code           13549 non-null  object \n",
      " 4   houses_sold    13455 non-null  float64\n",
      " 5   no_of_crimes   7439 non-null   float64\n",
      " 6   borough_flag   13549 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 741.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import housing data set:\n",
    "housing_df = pd.read_csv('../raw_data/housing_in_london_monthly_variables.csv')\n",
    "\n",
    "# Understand data set structure:\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make date datetime object:\n",
    "housing_df['date'] = pd.to_datetime(housing_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN values noticeable in houses_sold and no_of_crimes.  \n",
    "NaN houses_sold to be analysed; \n",
    "no_of_crimes not expected to be required in this EDA and disregarded for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand area and code referents:\n",
    "sales_per_area = housing_df['houses_sold'].groupby(housing_df['area']).sum().sort_values(ascending=False)\n",
    "housing_df['area'].unique()\n",
    "unique_codes = housing_df['code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains data for England at four levels: Country, England NUTS I, London Inner and Outer, London Borough.\n",
    "The data overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hypothesis that codes beginning E090... are London:\n",
    "codes = housing_df['area'].groupby(housing_df['code']).unique()\n",
    "\n",
    "# Consider area names when code starts 'E090':\n",
    "london_boroughs = housing_df[housing_df['code'].str.startswith('E090')]\n",
    "london_boroughs['area'].unique()\n",
    "\n",
    "# Categorise areas into the four types:\n",
    "gss_map = {'E09': 'London Borough', 'E12': 'English Region', 'E13': 'Inner/Outer London', 'E92': 'Country'}\n",
    "housing_df['GSS_prefix'] = housing_df['code'].str[:3]\n",
    "housing_df['area_type'] = housing_df['GSS_prefix'].map(gss_map)\n",
    "housing_df[housing_df['area_type'] == 'Country']\n",
    "sales_by_area_type = housing_df['houses_sold'].groupby(housing_df['area_type']).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English Region numbers show fewer houses sold than in Country, when they should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List regions:\n",
    "regions = housing_df['area'][housing_df['area_type'] == 'English Region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hackney appears incorrectly as English region i.e. incorrectly listed against 'E13' code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify if \"hackney\" area appearing as both borough and region is duplication:\n",
    "hackney = housing_df[housing_df['area'].str.contains('hackney')]\n",
    "hackney[hackney['area_type'] == 'English Region']\n",
    "hackney[hackney['date'] == '1998-04-01']\n",
    "\n",
    "# Remove duplicate entry:\n",
    "duplicate = housing_df[(housing_df['area'] == 'hackney') & (housing_df['area_type'] == 'English Region') \n",
    "& (housing_df['date'] == '1998-04-01')]\n",
    "clean_housing_df = housing_df.drop([3354])\n",
    "\n",
    "# Check removal:\n",
    "check = clean_housing_df['area'].groupby(clean_housing_df['code']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine and resolve other NaN in 'houses_sold':\n",
    "missing_values = clean_housing_df.isna().sum()\n",
    "missing_sales_numbers = clean_housing_df[clean_housing_df['houses_sold'].isnull() == True]\n",
    "clean_housing_df.set_index('date', inplace=True, drop=False)\n",
    "dec19_jan20 = clean_housing_df.loc['2019-12-01' : '2020-01-01']\n",
    "nineties_enfield = clean_housing_df[clean_housing_df['area'] == 'enfield'].loc['1995-09-01':'1996-03-01']\n",
    "nineties_tower_hamlets = clean_housing_df[clean_housing_df['area'] == 'tower hamlets'].loc['1995-09-01':'1996-03-01']\n",
    "se = clean_housing_df[clean_housing_df['code'] == 'E09000012'].loc['1998-01-01':'1998-06-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see three reasons for NaN values in 'houses_sold':\n",
    "1. No data is available yet for Dec 2019 and Jan 2020;\n",
    "2. Enfield and Tower Hamlets both have duplicate entries for 1996-02-01; \n",
    "3. Hackney has a duplicate entry for 1998-04-01.\n",
    "\n",
    "I am now confident that remaining rows containing ['houses_sold'] == NaN can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN:\n",
    "clean_housing_df.dropna(subset=['houses_sold'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to look at regions (data output to csv for further analysis):\n",
    "regions = clean_housing_df[clean_housing_df['area_type'] == 'English Region']\n",
    "region_df = regions[['area', 'average_price', 'houses_sold']].groupby('area').resample('A').agg({'average_price': 'mean', 'houses_sold': 'sum'})\n",
    "region_df.to_csv('../raw_data/regions_dataset.csv')\n",
    "\n",
    "# Filter to look at London boroughs (data output to csv for further analysis):\n",
    "boroughs = clean_housing_df[clean_housing_df['area_type'] == 'London Borough']\n",
    "boroughs[['area', 'average_price', 'houses_sold']].to_csv('../raw_data/borough_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
